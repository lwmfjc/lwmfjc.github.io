<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>随记</title><link>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/</link><description>Recent content on 随记</description><generator>Hugo</generator><language>zh</language><atom:link href="https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/index.xml" rel="self" type="application/rss+xml"/><item><title>CAP &amp; BASE理论详解</title><link>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/cap-and-base-theorem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/cap-and-base-theorem/</guid><description>&lt;p>经历过技术面试的小伙伴想必对 CAP &amp;amp; BASE 这个两个理论已经再熟悉不过了！&lt;/p>
&lt;p>我当年参加面试的时候，不夸张地说，只要问到分布式相关的内容，面试官几乎是必定会问这两个分布式相关的理论。一是因为这两个分布式基础理论是学习分布式知识的必备前置基础，二是因为很多面试官自己比较熟悉这两个理论（方便提问）。&lt;/p>
&lt;p>我们非常有必要将这两个理论搞懂，并且能够用自己的理解给别人讲出来。&lt;/p>
&lt;h2 id="cap-理论">
 CAP 理论
 &lt;a class="anchor" href="#cap-%e7%90%86%e8%ae%ba">#&lt;/a>
&lt;/h2>
&lt;p>
&lt;a target="_blank" href="https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86">CAP 理论/定理&lt;/a>起源于 2000 年，由加州大学伯克利分校的 Eric Brewer 教授在分布式计算原理研讨会（PODC）上提出，因此 CAP 定理又被称作 &lt;mark>布鲁尔定理（Brewer’s theorem）&lt;/mark>&lt;/p>
&lt;p>2 年后，麻省理工学院的 Seth Gilbert 和 Nancy Lynch 发表了布鲁尔猜想的证明，CAP 理论正式成为分布式领域的定理。&lt;/p>
&lt;h3 id="简介">
 简介
 &lt;a class="anchor" href="#%e7%ae%80%e4%bb%8b">#&lt;/a>
&lt;/h3>
&lt;p>&lt;mark>CAP&lt;/mark> 也就是 &lt;mark>Consistency（一致性）&lt;/mark>、&lt;mark>Availability（可用性）&lt;/mark>、&lt;mark>Partition Tolerance（分区容错性）&lt;/mark> 这三个单词首字母组合。&lt;/p>
&lt;p>&lt;img src="img/f051d08591c181c1a0908e705777ebf5_MD5.jpg" alt="" />&lt;/p>
&lt;p>CAP 理论的提出者布鲁尔在提出 CAP 猜想的时候，并没有详细定义 &lt;mark>Consistency&lt;/mark>、&lt;mark>Availability&lt;/mark>、&lt;mark>Partition Tolerance&lt;/mark> 三个单词的明确定义。&lt;/p>
&lt;p>因此，对于 CAP 的民间解读有很多，一般比较被大家推荐的是下面 👇 这种版本的解读。&lt;/p>
&lt;p>在理论计算机科学中，CAP 定理（CAP theorem）指出对于一个分布式系统来说，当设计读写操作时，只能同时满足以下三点中的两个：&lt;/p>
&lt;ul>
&lt;li>&lt;mark>一致性（Consistency）&lt;/mark> : 所有节点访问同一份最新的数据副本&lt;/li>
&lt;li>&lt;mark>可用性（Availability）&lt;/mark>: 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。&lt;/li>
&lt;li>&lt;mark>分区容错性（Partition Tolerance）&lt;/mark> : 分布式系统出现网络分区的时候，仍然能够对外提供服务。&lt;/li>
&lt;/ul>
&lt;p>&lt;mark>什么是网络分区？&lt;/mark>&lt;/p>
&lt;p>分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 &lt;mark>网络分区&lt;/mark>。&lt;/p>
&lt;p>&lt;img src="img/09697793be408e1fcaf6ddf700fe3a19_MD5.jpg" alt="partition-tolerance" />&lt;/p>
&lt;h3 id="不是所谓的3-选-2">
 不是所谓的“3 选 2”
 &lt;a class="anchor" href="#%e4%b8%8d%e6%98%af%e6%89%80%e8%b0%93%e7%9a%843-%e9%80%89-2">#&lt;/a>
&lt;/h3>
&lt;p>大部分人解释这一定律时，常常简单的表述为：“一致性、可用性、分区容忍性三者你只能同时达到其中两个，不可能同时达到”。实际上这是一个非常具有误导性质的说法，而且在 CAP 理论诞生 12 年之后，CAP 之父也在 2012 年重写了之前的论文。&lt;/p></description></item><item><title>Gossip 协议详解</title><link>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/gossip-protocl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/gossip-protocl/</guid><description>&lt;h2 id="背景">
 背景
 &lt;a class="anchor" href="#%e8%83%8c%e6%99%af">#&lt;/a>
&lt;/h2>
&lt;p>在分布式系统中，不同的节点进行数据/信息共享是一个基本的需求。&lt;/p>
&lt;p>一种比较简单粗暴的方法就是 &lt;mark>集中式发散消息&lt;/mark>，简单来说就是一个主节点同时共享最新信息给其他所有节点，比较适合中心化系统。这种方法的缺陷也很明显，节点多的时候不光同步消息的效率低，还太依赖与中心节点，存在单点风险问题。&lt;/p>
&lt;p>于是，&lt;mark>分散式发散消息&lt;/mark> 的 &lt;mark>Gossip 协议&lt;/mark> 就诞生了。&lt;/p>
&lt;h2 id="gossip-协议介绍">
 Gossip 协议介绍
 &lt;a class="anchor" href="#gossip-%e5%8d%8f%e8%ae%ae%e4%bb%8b%e7%bb%8d">#&lt;/a>
&lt;/h2>
&lt;p>Gossip 直译过来就是闲话、流言蜚语的意思。流言蜚语有什么特点呢？容易被传播且传播速度还快，你传我我传他，然后大家都知道了。&lt;/p>
&lt;p>&lt;img src="./images/gossip/gossip.png" alt="" />&lt;/p>
&lt;p>&lt;mark>Gossip 协议&lt;/mark> 也叫 Epidemic 协议（流行病协议）或者 Epidemic propagation 算法（疫情传播算法），别名很多。不过，这些名字的特点都具有 &lt;mark>随机传播特性&lt;/mark> （联想一下病毒传播、癌细胞扩散等生活中常见的情景），这也正是 Gossip 协议最主要的特点。&lt;/p>
&lt;p>Gossip 协议最早是在 ACM 上的一篇 1987 年发表的论文 
&lt;a target="_blank" href="https://dl.acm.org/doi/10.1145/41840.41841">《Epidemic Algorithms for Replicated Database Maintenance》&lt;/a>中被提出的。根据论文标题，我们大概就能知道 Gossip 协议当时提出的主要应用是在分布式数据库系统中各个副本节点同步数据。&lt;/p>
&lt;p>正如 Gossip 协议其名一样，这是一种随机且带有传染性的方式将信息传播到整个网络中，并在一定时间内，使得系统内的所有节点数据一致。&lt;/p>
&lt;p>在 Gossip 协议下，没有所谓的中心节点，每个节点周期性地随机找一个节点互相同步彼此的信息，理论上来说，各个节点的状态最终会保持一致。&lt;/p>
&lt;p>下面我们来对 Gossip 协议的定义做一个总结：&lt;mark>Gossip 协议是一种允许在分布式系统中共享状态的去中心化通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。&lt;/mark>&lt;/p>
&lt;h2 id="gossip-协议应用">
 Gossip 协议应用
 &lt;a class="anchor" href="#gossip-%e5%8d%8f%e8%ae%ae%e5%ba%94%e7%94%a8">#&lt;/a>
&lt;/h2>
&lt;p>NoSQL 数据库 Redis 和 Apache Cassandra、服务网格解决方案 Consul 等知名项目都用到了 Gossip 协议，学习 Gossip 协议有助于我们搞清很多技术的底层原理。&lt;/p></description></item><item><title>Paxos 算法详解</title><link>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/paxos-algorithm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/paxos-algorithm/</guid><description>&lt;h2 id="背景">
 背景
 &lt;a class="anchor" href="#%e8%83%8c%e6%99%af">#&lt;/a>
&lt;/h2>
&lt;p>Paxos 算法是 Leslie Lamport（
&lt;a target="_blank" href="https://zh.wikipedia.org/wiki/%E8%8E%B1%E6%96%AF%E5%88%A9%C2%B7%E5%85%B0%E4%BC%AF%E7%89%B9">莱斯利·兰伯特&lt;/a>）在 &lt;mark>1990&lt;/mark> 年提出了一种分布式系统 &lt;mark>共识&lt;/mark> 算法。这也是第一个被证明完备的共识算法（前提是不存在拜占庭将军问题，也就是没有恶意节点）。&lt;/p>
&lt;p>为了介绍 Paxos 算法，兰伯特专门写了一篇幽默风趣的论文。在这篇论文中，他虚拟了一个叫做 Paxos 的希腊城邦来更形象化地介绍 Paxos 算法。&lt;/p>
&lt;p>不过，审稿人并不认可这篇论文的幽默。于是，他们就给兰伯特说：“如果你想要成功发表这篇论文的话，必须删除所有 Paxos 相关的故事背景”。兰伯特一听就不开心了：“我凭什么修改啊，你们这些审稿人就是缺乏幽默细胞，发不了就不发了呗！”。&lt;/p>
&lt;p>于是乎，提出 Paxos 算法的那篇论文在当时并没有被成功发表。&lt;/p>
&lt;p>直到 1998 年，系统研究中心 (Systems Research Center，SRC）的两个技术研究员需要找一些合适的分布式算法来服务他们正在构建的分布式系统，Paxos 算法刚好可以解决他们的部分需求。因此，兰伯特就把论文发给了他们。在看了论文之后，这俩大佬觉得论文还是挺不错的。于是，兰伯特在 &lt;mark>1998&lt;/mark> 年重新发表论文 
&lt;a target="_blank" href="http://lamport.azurewebsites.net/pubs/lamport-paxos.pdf">《The Part-Time Parliament》&lt;/a>。&lt;/p>
&lt;p>论文发表之后，各路学者直呼看不懂，言语中还略显调侃之意。这谁忍得了，在 &lt;mark>2001&lt;/mark> 年的时候，兰伯特专门又写了一篇 
&lt;a target="_blank" href="http://lamport.azurewebsites.net/pubs/paxos-simple.pdf">《Paxos Made Simple》&lt;/a> 的论文来简化对 Paxos 的介绍，主要讲述两阶段共识协议部分，顺便还不忘嘲讽一下这群学者。&lt;/p>
&lt;p>《Paxos Made Simple》这篇论文就 14 页，相比于 《The Part-Time Parliament》的 33 页精简了不少。最关键的是这篇论文的摘要就一句话：&lt;/p>
&lt;p>&lt;img src="./images/paxos/paxos-made-simple.png" alt="" />&lt;/p>
&lt;blockquote>
&lt;p>The Paxos algorithm, when presented in plain English, is very simple.&lt;/p>
&lt;/blockquote>
&lt;p>翻译过来的意思大概就是：当我用无修饰的英文来描述时，Paxos 算法真心简单！&lt;/p>
&lt;p>有没有感觉到来自兰伯特大佬满满地嘲讽的味道？&lt;/p>
&lt;h2 id="介绍">
 介绍
 &lt;a class="anchor" href="#%e4%bb%8b%e7%bb%8d">#&lt;/a>
&lt;/h2>
&lt;p>Paxos 算法是第一个被证明完备的分布式系统共识算法。共识算法的作用是让分布式系统中的多个节点之间对某个提案（Proposal）达成一致的看法。提案的含义在分布式系统中十分宽泛，像哪一个节点是 Leader 节点、多个事件发生的顺序等等都可以是一个提案。&lt;/p></description></item><item><title>Raft 算法详解</title><link>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/raft-algorithm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://lwmfjc.github.io/zh/docs/technology/Interview/distributed-system/protocol/raft-algorithm/</guid><description>&lt;blockquote>
&lt;p>本文由 
&lt;a target="_blank" href="https://github.com/Snailclimb">SnailClimb&lt;/a> 和 
&lt;a target="_blank" href="https://github.com/jun0315">Xieqijun&lt;/a> 共同完成。&lt;/p>
&lt;/blockquote>
&lt;h2 id="1-背景">
 1 背景
 &lt;a class="anchor" href="#1-%e8%83%8c%e6%99%af">#&lt;/a>
&lt;/h2>
&lt;p>当今的数据中心和应用程序在高度动态的环境中运行，为了应对高度动态的环境，它们通过额外的服务器进行横向扩展，并且根据需求进行扩展和收缩。同时，服务器和网络故障也很常见。&lt;/p>
&lt;p>因此，系统必须在正常操作期间处理服务器的上下线。它们必须对变故做出反应并在几秒钟内自动适应；对客户来说的话，明显的中断通常是不可接受的。&lt;/p>
&lt;p>幸运的是，分布式共识可以帮助应对这些挑战。&lt;/p>
&lt;h3 id="11-拜占庭将军">
 1.1 拜占庭将军
 &lt;a class="anchor" href="#11-%e6%8b%9c%e5%8d%a0%e5%ba%ad%e5%b0%86%e5%86%9b">#&lt;/a>
&lt;/h3>
&lt;p>在介绍共识算法之前，先介绍一个简化版拜占庭将军的例子来帮助理解共识算法。&lt;/p>
&lt;blockquote>
&lt;p>假设多位拜占庭将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成是否要进攻的一致性决定？&lt;/p>
&lt;/blockquote>
&lt;p>解决方案大致可以理解成：先在所有的将军中选出一个大将军，用来做出所有的决定。&lt;/p>
&lt;p>举例如下：假如现在一共有 3 个将军 A，B 和 C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就把自己当成大将军候选人，然后派信使传递选举投票的信息给将军 B 和 C，如果将军 B 和 C 还没有把自己当作候选人（自己的倒计时还没有结束），并且没有把选举票投给其他人，它们就会把票投给将军 A，信使回到将军 A 时，将军 A 知道自己收到了足够的票数，成为大将军。在有了大将军之后，是否需要进攻就由大将军 A 决定，然后再去派信使通知另外两个将军，自己已经成为了大将军。如果一段时间还没收到将军 B 和 C 的回复（信使可能会被暗杀），那就再重派一个信使，直到收到回复。&lt;/p>
&lt;h3 id="12-共识算法">
 1.2 共识算法
 &lt;a class="anchor" href="#12-%e5%85%b1%e8%af%86%e7%ae%97%e6%b3%95">#&lt;/a>
&lt;/h3>
&lt;p>共识是可容错系统中的一个基本问题：即使面对故障，服务器也可以在共享状态上达成一致。&lt;/p>
&lt;p>共识算法允许一组节点像一个整体一样一起工作，即使其中的一些节点出现故障也能够继续工作下去，其正确性主要是源于复制状态机的性质：一组&lt;code>Server&lt;/code>的状态机计算相同状态的副本，即使有一部分的&lt;code>Server&lt;/code>宕机了它们仍然能够继续运行。&lt;/p>
&lt;p>&lt;img src="img/e53237d8af56aa6747ea8c2520070fbd_MD5.jpg" alt="rsm-architecture.png" />&lt;/p>
&lt;p>&lt;code>图-1 复制状态机架构&lt;/code>&lt;/p>
&lt;p>一般通过使用复制日志来实现复制状态机。每个&lt;code>Server&lt;/code>存储着一份包括命令序列的日志文件，状态机会按顺序执行这些命令。因为每个日志包含相同的命令，并且顺序也相同，所以每个状态机处理相同的命令序列。由于状态机是确定性的，所以处理相同的状态，得到相同的输出。&lt;/p>
&lt;p>因此共识算法的工作就是保持复制日志的一致性。服务器上的共识模块从客户端接收命令并将它们添加到日志中。它与其他服务器上的共识模块通信，以确保即使某些服务器发生故障。每个日志最终包含相同顺序的请求。一旦命令被正确地复制，它们就被称为已提交。每个服务器的状态机按照日志顺序处理已提交的命令，并将输出返回给客户端，因此，这些服务器形成了一个单一的、高度可靠的状态机。&lt;/p>
&lt;p>适用于实际系统的共识算法通常具有以下特性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>安全。确保在非拜占庭条件（也就是上文中提到的简易版拜占庭）下的安全性，包括网络延迟、分区、包丢失、复制和重新排序。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>高可用。只要大多数服务器都是可操作的，并且可以相互通信，也可以与客户端进行通信，那么这些服务器就可以看作完全功能可用的。因此，一个典型的由五台服务器组成的集群可以容忍任何两台服务器端故障。假设服务器因停止而发生故障；它们稍后可能会从稳定存储上的状态中恢复并重新加入集群。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>一致性不依赖时序。错误的时钟和极端的消息延迟，在最坏的情况下也只会造成可用性问题，而不会产生一致性问题。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在集群中大多数服务器响应，命令就可以完成，不会被少数运行缓慢的服务器来影响整体系统性能。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="2-基础">
 2 基础
 &lt;a class="anchor" href="#2-%e5%9f%ba%e7%a1%80">#&lt;/a>
&lt;/h2>
&lt;h3 id="21-节点类型">
 2.1 节点类型
 &lt;a class="anchor" href="#21-%e8%8a%82%e7%82%b9%e7%b1%bb%e5%9e%8b">#&lt;/a>
&lt;/h3>
&lt;p>一个 Raft 集群包括若干服务器，以典型的 5 服务器集群举例。在任意的时间，每个服务器一定会处于以下三个状态中的一个：&lt;/p></description></item></channel></rss>